{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQsUVzmrq0Rd",
        "outputId": "542c09eb-b58a-40dd-d012-636f22036a7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "import os\n",
        "\n",
        "# Path to dataset in your Drive\n",
        "data_path = \"/content/drive/MyDrive/farm_insects\"\n",
        "\n",
        "# Image generator with validation split and data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.15,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,  # Flip images horizontally\n",
        "    fill_mode='nearest'  # Fill missing pixels after transformation\n",
        ")\n",
        "\n",
        "# Load training and validation data with augmentation\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# CNN Model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),  # Dropout for regularization\n",
        "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# EarlyStopping to stop training if the validation loss doesn't improve\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Learning rate scheduler to reduce the learning rate after a certain number of epochs\n",
        "def lr_schedule(epoch, lr):\n",
        "    if epoch > 15:  # Decrease learning rate after 15 epochs\n",
        "        return lr * 0.5\n",
        "    return lr\n",
        "\n",
        "# Train the model with early stopping and learning rate scheduler\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping, LearningRateScheduler(lr_schedule)]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "val_loss, val_acc = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxkH2kNHrHEm",
        "outputId": "f8d5b693-babb-4268-ada0-2f7e129736d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1348 images belonging to 15 classes.\n",
            "Found 231 images belonging to 15 classes.\n",
            "Epoch 1/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.0513 - loss: 2.7280 - val_accuracy: 0.0779 - val_loss: 2.7047 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.0754 - loss: 2.7041 - val_accuracy: 0.0606 - val_loss: 2.6963 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.0940 - loss: 2.6827 - val_accuracy: 0.0779 - val_loss: 2.7404 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.1001 - loss: 2.6511 - val_accuracy: 0.0952 - val_loss: 2.6050 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.1254 - loss: 2.5587 - val_accuracy: 0.1472 - val_loss: 2.5725 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.1189 - loss: 2.5429 - val_accuracy: 0.1299 - val_loss: 2.5820 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.1346 - loss: 2.5269 - val_accuracy: 0.1558 - val_loss: 2.5622 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.1539 - loss: 2.5085 - val_accuracy: 0.1515 - val_loss: 2.5222 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.1529 - loss: 2.4786 - val_accuracy: 0.1299 - val_loss: 2.5191 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.1465 - loss: 2.4632 - val_accuracy: 0.1472 - val_loss: 2.5050 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.2006 - loss: 2.4290 - val_accuracy: 0.1169 - val_loss: 2.4697 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.1566 - loss: 2.4351 - val_accuracy: 0.1948 - val_loss: 2.4333 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.2068 - loss: 2.3927 - val_accuracy: 0.1948 - val_loss: 2.3874 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.2134 - loss: 2.3706 - val_accuracy: 0.1775 - val_loss: 2.3577 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.2414 - loss: 2.3159 - val_accuracy: 0.1861 - val_loss: 2.4164 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.2043 - loss: 2.3655 - val_accuracy: 0.2121 - val_loss: 2.3676 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.2294 - loss: 2.2783 - val_accuracy: 0.2338 - val_loss: 2.3241 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.2618 - loss: 2.2456 - val_accuracy: 0.2208 - val_loss: 2.3198 - learning_rate: 2.5000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.2546 - loss: 2.2011 - val_accuracy: 0.2511 - val_loss: 2.2904 - learning_rate: 1.2500e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - accuracy: 0.2773 - loss: 2.1353 - val_accuracy: 0.2208 - val_loss: 2.3045 - learning_rate: 6.2500e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.2651 - loss: 2.1937 - val_accuracy: 0.2121 - val_loss: 2.3090 - learning_rate: 3.1250e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.2568 - loss: 2.2054 - val_accuracy: 0.2251 - val_loss: 2.2780 - learning_rate: 1.5625e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.2638 - loss: 2.2146 - val_accuracy: 0.2251 - val_loss: 2.3275 - learning_rate: 7.8125e-06\n",
            "Epoch 24/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.2947 - loss: 2.1358 - val_accuracy: 0.2727 - val_loss: 2.2841 - learning_rate: 3.9063e-06\n",
            "Epoch 25/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.2777 - loss: 2.1478 - val_accuracy: 0.2338 - val_loss: 2.2733 - learning_rate: 1.9531e-06\n",
            "Epoch 26/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.2794 - loss: 2.1653 - val_accuracy: 0.2121 - val_loss: 2.2995 - learning_rate: 9.7656e-07\n",
            "Epoch 27/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.2662 - loss: 2.1982 - val_accuracy: 0.2251 - val_loss: 2.3131 - learning_rate: 4.8828e-07\n",
            "Epoch 28/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.2719 - loss: 2.1551 - val_accuracy: 0.2208 - val_loss: 2.3137 - learning_rate: 2.4414e-07\n",
            "Epoch 29/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.2607 - loss: 2.1400 - val_accuracy: 0.2424 - val_loss: 2.2702 - learning_rate: 1.2207e-07\n",
            "Epoch 30/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.2793 - loss: 2.1882 - val_accuracy: 0.2165 - val_loss: 2.3122 - learning_rate: 6.1035e-08\n",
            "Epoch 31/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - accuracy: 0.2835 - loss: 2.1506 - val_accuracy: 0.2381 - val_loss: 2.2777 - learning_rate: 3.0518e-08\n",
            "Epoch 32/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.2505 - loss: 2.2272 - val_accuracy: 0.2511 - val_loss: 2.2951 - learning_rate: 1.5259e-08\n",
            "Epoch 33/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.2448 - loss: 2.2271 - val_accuracy: 0.2381 - val_loss: 2.2694 - learning_rate: 7.6294e-09\n",
            "Epoch 34/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.2639 - loss: 2.1721 - val_accuracy: 0.2251 - val_loss: 2.2847 - learning_rate: 3.8147e-09\n",
            "Epoch 35/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.2606 - loss: 2.1785 - val_accuracy: 0.2208 - val_loss: 2.3143 - learning_rate: 1.9073e-09\n",
            "Epoch 36/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.2515 - loss: 2.1873 - val_accuracy: 0.2381 - val_loss: 2.3106 - learning_rate: 9.5367e-10\n",
            "Epoch 37/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.2819 - loss: 2.1676 - val_accuracy: 0.2597 - val_loss: 2.3025 - learning_rate: 4.7684e-10\n",
            "Epoch 38/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.2809 - loss: 2.1678 - val_accuracy: 0.2208 - val_loss: 2.2775 - learning_rate: 2.3842e-10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 636ms/step - accuracy: 0.2398 - loss: 2.2095\n",
            "Validation Loss: 2.281965732574463, Validation Accuracy: 0.23376622796058655\n"
          ]
        }
      ]
    }
  ]
}